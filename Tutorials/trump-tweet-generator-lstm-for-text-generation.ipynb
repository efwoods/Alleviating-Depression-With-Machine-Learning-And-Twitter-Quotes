{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is very simple:\n",
    "__To show you how easy it is to train and use an LSTM for text generation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build the LSTM network described in https://keras.io/examples/lstm_text_generation/. \n",
    "If you want to learn more about LSTM, take a look at this post - http://colah.github.io/posts/2015-08-Understanding-LSTMs/.  \n",
    "The jist or it is that an LSTM does not only take a bunch of features and makes predicitons, but also takes the timeseries aspect of the features into consideration.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the LSTM on 7,000 of Trump's tweets and end up with a machine that can tweet like the president.  \n",
    "And again, __this is easier than it sounds!__\n",
    "# Steps\n",
    "## [Preprocessing](#1)\n",
    "1. Inspect and preprocess the tweets\n",
    "2. Create dictionary of available characters and assign indeces.\n",
    "3. Create training set. We need to build our training set such that our model gets as input N characters and needs to predict character N+1.\n",
    "4. Vectorization: This means turning a character into a one-hot vector. If we have 30 possible characters, the letter 'd' (the fourth letter) will be represented by a vector of size 30, where all the values are zero except the fourth which will be one. When we have a sentence of 40 characters, we will have 40 such vectors.  \n",
    "\n",
    "## [Model Building](#2)\n",
    "Easy peasy with Keras. 4 lines of code (more details once we get to that section).  \n",
    "We define some extra helper functions, train and score.  \n",
    "Since the model predicts letter N+1, we run scoring in a loop, and letter by letter, generate a presidential tweet.\n",
    "\n",
    "## [Experiment](#3)\n",
    "We built a basic network.  \n",
    "Let's try and improve with a bigger network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Donald-Tweets!.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7375, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Type</th>\n",
       "      <th>Media_Type</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet_Url</th>\n",
       "      <th>twt_favourites_IS_THIS_LIKE_QUESTION_MARK</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>15:26:37</td>\n",
       "      <td>Today we express our deepest gratitude to all ...</td>\n",
       "      <td>text</td>\n",
       "      <td>photo</td>\n",
       "      <td>ThankAVet</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>127213</td>\n",
       "      <td>41112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>13:33:35</td>\n",
       "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>141527</td>\n",
       "      <td>28654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>11:14:20</td>\n",
       "      <td>Love the fact that the small groups of protest...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>183729</td>\n",
       "      <td>50039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:19:44</td>\n",
       "      <td>Just had a very open and successful presidenti...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>214001</td>\n",
       "      <td>67010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:10:46</td>\n",
       "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>178499</td>\n",
       "      <td>36688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Time     ...     Unnamed: 10 Unnamed: 11\n",
       "0  16-11-11  15:26:37     ...             NaN         NaN\n",
       "1  16-11-11  13:33:35     ...             NaN         NaN\n",
       "2  16-11-11  11:14:20     ...             NaN         NaN\n",
       "3  16-11-11   2:19:44     ...             NaN         NaN\n",
       "4  16-11-11   2:10:46     ...             NaN         NaN\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "df = pd.read_csv('../input/Donald-Tweets!.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Inspect Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all\n",
    "text = df['Tweet_Text'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### any sentences we want to drop?\n",
    "we probably want to keep the hashtags, but if there are for example random characters (like links), we want to drop them so they won't affct the precictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i will be on @meetthepress in an interview with @chucktodd on sunday morning. so much to talk about!',\n",
       "       '\"minorities line up behind donald trump\" #trump2016\\nhttps://t.co/clcvogwomy',\n",
       "       'make america great again!\\n#inprimary #votetrump\\nhttps://t.co/nmqekxccv6',\n",
       "       'thank you for all of your support iowa!\\n#makeamericagreatagain #trump2016\\n#iacaucus finder: https://t.co/anvtczqfoq https://t.co/fqaxume01b',\n",
       "       '\"every american needs to say 2 simple words to every vet they meet: thank you!\" john wayne walding\\nhttps://t.co/wg8ezphzt1',\n",
       "       'a suicide bomber has just killed u.s. troops in afghanistan. when will our leaders get tough and smart. we are being led to slaughter!',\n",
       "       'thank you, new hampshire! great people -- see you next week! https://t.co/r83xq8kxp5',\n",
       "       'during primetime of the iowa caucus, cruz put out a release that @realbencarson was quitting the race, and to caucus (or vote) for cruz.',\n",
       "       'thank you tennessee! #maga https://t.co/oodfmerq5b',\n",
       "       'rt @anncoulter: .@realdonaldtrump leads w/ hispanics. huckabee &amp; christie - who supported in-state tuition 4 illegals -scrape bottom. http:_'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "np.random.choice(text,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      "today we express our deepest gratitude to all those who have served in our armed forces. #thankavet https://t.co/wpk7qwpk8z\n",
      "AFTER:\n",
      "today we express our deepest gratitude to all those who have served in our armed forces. #thankavet\n"
     ]
    }
   ],
   "source": [
    "print('BEFORE:')\n",
    "print(text[0])\n",
    "text = text.map(lambda s: ' '.join([x for x in s.split() if 'http' not in x]))\n",
    "print('AFTER:')\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emojis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any super short tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tweet len: 151\n",
      "min tweet len: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('max tweet len:',text.map(len).max())\n",
    "print('min tweet len:',text.map(len).min())\n",
    "text.map(len).hist();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only tweets of over 60 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text[text.map(len)>60]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Chars Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 78\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(text))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'ʉ',\n",
       " '̱',\n",
       " 'ω',\n",
       " 'я',\n",
       " 'ӕ',\n",
       " 'ԍ',\n",
       " 'ԏ',\n",
       " 'ԡ',\n",
       " 'լ',\n",
       " 'ջ',\n",
       " 'ُ',\n",
       " '٪',\n",
       " '\\u06dd',\n",
       " 'ۢ',\n",
       " '۪']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe last ones are emojis?  \n",
    "Let's take a look at sentences with the weird chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHAR: {\n",
      "['\"{crooked hillary clinton} created this mess, and she knows it.\" #draintheswamp']\n",
      "\n",
      "CHAR: |\n",
      "['\"@redletter99: trump pummels his opponents - and the press | sunherald @realdonaldtrump thank you!', 'rt @danscavino: 2016 gop primary hp tracking 139 polls | 28 pollsters. #1 trump 24.1% #2 bush 10.7% #3 carson 8.6% #4 rubio 6.8%', 'join me in florida tomorrow! #makeamericagreatagain daytona | 3pm- jacksonville | 7pm-']\n",
      "\n",
      "CHAR: }\n",
      "['\"{crooked hillary clinton} created this mess, and she knows it.\" #draintheswamp']\n",
      "\n",
      "CHAR: ~\n",
      "['join me in roanoke, virginia tomorrow at the berglund center- coliseum ~ 6pm! tickets available at:_', 'rt @danscavino: #icymi ~ double digit #gop leader @realdonaldtrumps ۢ speech today in #iowa _ #1 trump @ 28% #2 @s_', '\"@destiny: why didnt @seanhannity correct jeb when he said @realdonaldtrump has run 4 president 2x b4~jeb needs 2b corrected b/c he lied.\"']\n",
      "\n",
      "CHAR: ʉ\n",
      "['my pro-growth econ plan: eliminate excessive regulations! lean government! lower taxes! #debatesʉ_']\n",
      "\n",
      "CHAR: ̱\n",
      "['mexico has lost a brilliant finance minister and wonderful man who i know is highly respected by president pe̱a nieto.']\n",
      "\n",
      "CHAR: ω\n",
      "['via @breitbartnews by steve bannon: ωtime to get tough۪: trump۪s blockbuster policy manifesto\\u06dd']\n",
      "\n",
      "CHAR: я\n",
      "['\"@tn_riverfolk: my 2016 vote will b based on #makeamericagreatagain not eminent domainяamericans need 2prioritize']\n",
      "\n",
      "CHAR: ӕ\n",
      "['fact ӕ on red line\\u06dd in syria: hrc \"i wasn۪t there.\" fact: line drawn in aug ۪12. hrc secy of state til feb ۪13.', 'rt @teamtrump: #rattledhillary wants to talk about her 30 years in service. how about her 30 years of flopsӕflops?! #bigleaguetruth #debat_']\n",
      "\n",
      "CHAR: ԍ\n",
      "['\"@curtandkaren: kudos to @megynkelly and @realdonaldtrump for rising above the drama and coming together. very respectful and classy _ԍ\"', '\"@bentleyfortrump: @realdonaldtrump all of america loves trump!_ԍ_ԍ #trumpornobody2016 #makeamericagreatagain\" thank you.', '\"@dboiarsky: @realdonaldtrump make america great again, dt! _ԍ\"']\n",
      "\n",
      "CHAR: ԏ\n",
      "['\"@repalonelori: @realdonaldtrump @kirstiealley we love you and know you will do an awesome job! saw you in bethpage !! _ԏ_ԏ_ԏ\" thank you.']\n",
      "\n",
      "CHAR: ԡ\n",
      "['\"@good2bqueen67: .@realdonaldtrump @sandikay60 i enjoyed the speech so much tonight, you were on point _ԡ sir!\" thanks.']\n",
      "\n",
      "CHAR: լ\n",
      "['rt @erictrump: #wisconsin: to find your voting location visit #makeamericagreatagain #trumptrain ___լ_լ______']\n",
      "\n",
      "CHAR: ջ\n",
      "['rt @darrenjjordan: constructive wins! _ջ @realdonaldtrump @clewandowski_ @danscavino @michaelcohen212 @katrinapierson @defendingtheusa']\n",
      "\n",
      "CHAR: ُ\n",
      "['\"@plruble58 @realdonaldtrump the numbers are amazing! #gogogo_ُ\"', '\"@hbtc23: @realdonaldtrump backs down from nobody!! #makeamericagreatagain #trump2016 @steveaustinbsr @wwe __ _٪_ُ', '\"@trumpsmyhomeboy: @realdonaldtrump @robostop10 @politico the #msm straw man candidate is falling apart!___ُ_\"']\n",
      "\n",
      "CHAR: ٪\n",
      "['\"@hbtc23: @realdonaldtrump backs down from nobody!! #makeamericagreatagain #trump2016 @steveaustinbsr @wwe __ _٪_ُ']\n",
      "\n",
      "CHAR: ۝\n",
      "['ron fournier: \"clinton used secret server to protect #circleofenrichment\\u06dd', '\"@ilduce2016: it is better to live one day as a lion than 100 years as a sheep.\\u06dd @realdonaldtrump #makeamericagreatagain\"', 'via @politico by poll: trump has twice the support of bush in new hampshire\\u06dd']\n",
      "\n",
      "CHAR: ۢ\n",
      "['rt @danscavino: #breaking #abc #news ۢ #washington, releases poll @ 5pet with @realdonaldtrump at 24% &amp; 2nd place coming in at 13%...', '\"@danscavino: via economist/yougov 7ۢ24ۢ2015 #makeamericagreatagain #trump2016\"', 'you do not want to miss @barbarajwalters 10 most fascinating people of 2015 @abc ۢ 9:30pme.']\n",
      "\n",
      "CHAR: ۪\n",
      "['carl icahn said this about me: \"i think at this moment in time, he۪s the only candidate that speaks out about the country۪s problems.\"', 'the horrible shooting that took place in san bernardino was an absolute act of terror that many people knew about. why didn۪t they report?', 'hillary clinton۪s presidency would be catastrophic for the future of our country. she is ill-fit with bad judgment.']\n"
     ]
    }
   ],
   "source": [
    "for c in chars[-19:]:\n",
    "    print('\\nCHAR:', c)\n",
    "    smple = [x for x in text if c in x]\n",
    "    print(random.sample(smple,min(3,len(smple))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still weird....  \n",
    "let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for c in chars[-19:]:\n",
    "    text = text.str.replace(c,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(text))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Input Data\n",
    "input - 40 characters of a tweet  \n",
    "output - next character  \n",
    "(make sure we don't combine different tweets into same corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 472774\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for x in text:\n",
    "    for i in range(0, len(x) - maxlen, step):\n",
    "        sentences.append(x[i: i + maxlen])\n",
    "        next_chars.append(x[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today we express our deepest gratitude t ==> o\n",
      "oday we express our deepest gratitude to ==>  \n",
      "day we express our deepest gratitude to  ==> a\n"
     ]
    }
   ],
   "source": [
    "## check example\n",
    "for i in range(3):\n",
    "    print(sentences[i],'==>',next_chars[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today we express our deepest gratitude to all those who have served in our armed forces. #thankavet'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "1. Turn X into matrix of (numer_of_sentences,max_len_of_sentence,num_chars).  \n",
    "If char i is number j char in sentence k, there will be a 1 in location (k,j,i)\n",
    "2. Turn y into a vector of (number_of_sentences,num_chars).  \n",
    "If character z is the next character in sentence k, there will be a 1 in locaiton (k,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# build the model: a single LSTM\n",
    "1. Define we have a sequential model\n",
    "2. Add an LSTM layer with 128 units. Input shape is a matrix of `maxlen` characters, where each character is a vector of `len(chars)`\n",
    "3. Add a dense layer (fully connected layer) and have the softmax activation pick a winner from the `len(chars)` possible characters.\n",
    "4. Pick an optimizer for the network and choose `categorical_crossentropy` loss function (used in multiclass classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler\n",
    "We don't want the next character to be the one with the highest probaility (we'll get the same results every time).  \n",
    "So we sample with temperature parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of what the function does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for temperature in [0.1, 0.2, 0.3,  0.5, 1.0, 1.2, 1.3]:\n",
    "    print(sample([.1,.3,.5,.1],temperature=temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gave the function an array where highest probability was index number 2 (.5).  \n",
    "When temperature was low, we got what we expected.  \n",
    "As we increased the temperature, the function got more creative license choosing the max.  \n",
    "So:\n",
    "* temperature helps us not get the same text generated every time\n",
    "* low temperature = text similar to trained data\n",
    "* high temperature = more creative generation\n",
    "* too high temperature = nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text at Epoch End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    tweet = np.random.choice(text) # select random tweet\n",
    "    start_index = 0\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = tweet[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(120):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "472774/472774 [==============================] - 212s 448us/step - loss: 2.3554\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"join me tomorrow! #trump2016 #makeameric\"\n",
      "join me tomorrow! #trump2016 #makeamericagreatagain #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump201\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"join me tomorrow! #trump2016 #makeameric\"\n",
      "join me tomorrow! #trump2016 #makeamericagreatagain! #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #trump2016 #gringater the mall and ijont \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"join me tomorrow! #trump2016 #makeameric\"\n",
      "join me tomorrow! #trump2016 #makeamericagreasagain\" jo the patee: ox ane inatre tha4 gin the un butc. gom! w/ @pealdorumpatari, by. to heveren on fur fiow lovi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"join me tomorrow! #trump2016 #makeameric\"\n",
      "join me tomorrow! #trump2016 #makeamerica5galbiathe reeridey donelefain. @faryoncurd wuthe!\" aug in! ale tremesent hoegeest @rdating frock #botonilly athaig tou\n",
      "Epoch 2/5\n",
      "286080/472774 [=================>............] - ETA: 1:21 - loss: 1.9635"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# Can we get better results on a bigger network?\n",
    "* Add epochs for better model\n",
    "* Add another LSTM layer and dropouts to avoid overfitting.  \n",
    "* Make sure to set `return_sequences` to True on the first LSTM layer so it will return the entire sequence not just the last output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape=(maxlen, len(chars)),return_sequences=True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam()\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "472774/472774 [==============================] - 408s 863us/step - loss: 2.2799\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"big wins in west virginia and nebraska. \"\n",
      "big wins in west virginia and nebraska. #trump2016 #trump2016 #trump2016 #trump2016 #makeamericagreatagain #trump2016 #makeamericagreatagain #trump2016 #trump20\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"big wins in west virginia and nebraska. \"\n",
      "big wins in west virginia and nebraska. #trump2016 #makeamericagreatagain #trump2016 #trump2016\" the gop ratings on illegal will for the republican leader stall\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"big wins in west virginia and nebraska. \"\n",
      "big wins in west virginia and nebraska. hellar. @denderjubines @aresilway2016\" 11/149 8ly the antthert my wonts $5:00. i joth prioblemp wears! jodrelowiesedn- a\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"big wins in west virginia and nebraska. \"\n",
      "big wins in west virginia and nebraska. it where youre. gom! @wencarif? outlion run sommingon jobssemperfus, who hishond ben abe &amp; dive incandig tonevor\" yo\n",
      "Epoch 2/60\n",
      "472774/472774 [==============================] - 407s 861us/step - loss: 1.8205\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"\"@fairess369: it is a sad commentary lit\"\n",
      "\"@fairess369: it is a sad commentary litter that the was the president of the will be a great and her start the was the great with the great and the was the wor\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\"@fairess369: it is a sad commentary lit\"\n",
      "\"@fairess369: it is a sad commentary litter in show news we will be a great has me states are the wass or mesise and vote the promeryon on tone the was not i wa\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"\"@fairess369: it is a sad commentary lit\"\n",
      "\"@fairess369: it is a sad commentary little out parta, and kny fatceed to gult!\" so tomerly. its @realdonaldtrump is @hervinge toughona. are peypan #1. his lead\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"\"@fairess369: it is a sad commentary lit\"\n",
      "\"@fairess369: it is a sad commentary litted! #trump2016 i alligatont-to wenk 41%ure! . great debaicse inhelled. cordorge fit a bballys with the cares facty --if\n",
      "Epoch 3/60\n",
      "472774/472774 [==============================] - 410s 867us/step - loss: 1.6767\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"crookeds stop in johnstown, pennsylvania\"\n",
      "crookeds stop in johnstown, pennsylvania show the problems with the people on the people who wants the republican problems who can all the the problems of the p\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"crookeds stop in johnstown, pennsylvania\"\n",
      "crookeds stop in johnstown, pennsylvania so for the only me to all her cruz win the people on the real will be a grought highonest with all on hes candidate tha\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"crookeds stop in johnstown, pennsylvania\"\n",
      "crookeds stop in johnstown, pennsylvania grive he waits dim - what and witcors! nol chinars. #trump2016 #eakerumb @mrithufailwouth, #tol there cincovidees by th\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"crookeds stop in johnstown, pennsylvania\"\n",
      "crookeds stop in johnstown, pennsylvanialeinis. so the mis of @dofardcamsia &amp; i aling o #crubigacnate los much goverec. debate was no sund.w. jeals those is\n",
      "Epoch 4/60\n",
      "122624/472774 [======>.......................] - ETA: 4:59 - loss: 1.6157"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model2.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Test Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_w_seed(sentence,diversity):\n",
    "    sentence = sentence[0:maxlen]\n",
    "    print(f'seed: {sentence}')\n",
    "    print(f'diversity: {diversity}')\n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    \n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(120):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: .@hillaryclinton - obama #isis strategy \n",
      "diversity: 0.2\n",
      ".@hillaryclinton - obama #isis strategy the was the people who will be angreating to the polls for the problem the promering the people who want to want to want\n",
      "\n",
      "seed: .@hillaryclinton - obama #isis strategy \n",
      "diversity: 0.5\n",
      ".@hillaryclinton - obama #isis strategy about endorsement was not reports on @realdonaldtrump the will be bought him borkent states and show beat the because th\n",
      "\n",
      "seed: .@hillaryclinton - obama #isis strategy \n",
      "diversity: 1.0\n",
      ".@hillaryclinton - obama #isis strategy trump\" therpe play new lease not but the they my up 7:002 - fasiderd alropee? #trump2016 clooken for strand way in prist\n",
      "\n",
      "seed: .@hillaryclinton - obama #isis strategy \n",
      "diversity: 1.2\n",
      ".@hillaryclinton - obama #isis strategy are bigweral/as carey the was big! exsiar! i reounty she he is?mil\" be that when aiscevinters--uestachoo,smorviews. @dbu\n",
      "\n",
      "seed: i had a great time in texas yesterday. a\n",
      "diversity: 0.2\n",
      "i had a great time in texas yesterday. and the was and the problemp the people and better that is a great and the people on the will be and new your prouders fo\n",
      "\n",
      "seed: i had a great time in texas yesterday. a\n",
      "diversity: 0.5\n",
      "i had a great time in texas yesterday. and the mess in the real and leaders not in next people in a caurly and and with not the problics with with all watch on \n",
      "\n",
      "seed: i had a great time in texas yesterday. a\n",
      "diversity: 1.0\n",
      "i had a great time in texas yesterday. and tonoght. media cruz. we have thereses? what our come boring on the doing loed! u in now vote wanth the sownont\"? mote\n",
      "\n",
      "seed: i had a great time in texas yesterday. a\n",
      "diversity: 1.2\n",
      "i had a great time in texas yesterday. abrovidement gop boushr! that have doinsty! not red groverilat phlidiyg on saccy abigh, hus carr have 20.t% rascion-\"s ha\n",
      "\n",
      "seed: rt @teamtrump: corruption confirmed: fbi\n",
      "diversity: 0.2\n",
      "rt @teamtrump: corruption confirmed: fbild to the problest the will be the the problest the world the people and the was a will be a great and the republican pr\n",
      "\n",
      "seed: rt @teamtrump: corruption confirmed: fbi\n",
      "diversity: 0.5\n",
      "rt @teamtrump: corruption confirmed: fbilly and the was me and chared and he get the people show not commentrowers candidates and they with unfor at the the usa\n",
      "\n",
      "seed: rt @teamtrump: corruption confirmed: fbi\n",
      "diversity: 1.0\n",
      "rt @teamtrump: corruption confirmed: fbiets turnor?\" therumo shein poll! this in-the.me. will we winded streve has! rate stirited storing a prosesh! great sonat\n",
      "\n",
      "seed: rt @teamtrump: corruption confirmed: fbi\n",
      "diversity: 1.2\n",
      "rt @teamtrump: corruption confirmed: fbimess as antame she) and fepnon blames, twotobsump for trump crimes kore stady blanker. 4 @readdonaldtrump will you winno\n",
      "\n",
      "seed: .@robertgbeckel please thank your brothe\n",
      "diversity: 0.2\n",
      ".@robertgbeckel please thank your brothers that is the mess and the problems who want to can dould to trump to the world the people who was he was the made the \n",
      "\n",
      "seed: .@robertgbeckel please thank your brothe\n",
      "diversity: 0.5\n",
      ".@robertgbeckel please thank your brothers that i will be the state was proper menion beat failed it as a rating her beat news, people on the failing the mest o\n",
      "\n",
      "seed: .@robertgbeckel please thank your brothe\n",
      "diversity: 1.0\n",
      ".@robertgbeckel please thank your brotheroles, interriver)! #13 #trump2016 #stape #twavestrump #nugrearnowhing work to y!! trump turge coundid!\" trade i winher \n",
      "\n",
      "seed: .@robertgbeckel please thank your brothe\n",
      "diversity: 1.2\n",
      ".@robertgbeckel please thank your brothernees. #camiothuppuba011_\"________\"cente7_\"2016\" her caidonts n! thark the. they a very sisting injiblictontled wamin. t\n",
      "\n",
      "seed: wow, two candidates called last night an\n",
      "diversity: 0.2\n",
      "wow, two candidates called last night and the will be a great and make america great again! #trump2016 #makeamericagreatagain #trump2016 #makeamericagreatagain \n",
      "\n",
      "seed: wow, two candidates called last night an\n",
      "diversity: 0.5\n",
      "wow, two candidates called last night and the we can the will be trump the only support the was and what he past the rebucked and a problem now cared in the pol\n",
      "\n",
      "seed: wow, two candidates called last night an\n",
      "diversity: 1.0\n",
      "wow, two candidates called last night any talk will could new. say falsorm). just for problelson, one gent araucus on kaigy towne trial. thanks. presidenting th\n",
      "\n",
      "seed: wow, two candidates called last night an\n",
      "diversity: 1.2\n",
      "wow, two candidates called last night anyfugu! toly he geved but cump-tonate.wu, very othercine. 1prenf: stop.\" presidenticiznavoted has bellotivepisteech. he w\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in random.sample(list(text),5):\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        generate_w_seed(s,diversity)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the model is not perfect, but this was a quick baseline model.  \n",
    "Things that can help with this and any other LSTM\n",
    "* adding more data (Kaggle has more Trumpian corpus that can help train our generator)\n",
    "* increase the network size\n",
    "* train longer\n",
    "* use more sophisticated architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
